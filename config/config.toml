# Global LLM configuration
[llm]
model = "deepseek-chat"
base_url = "https://api.deepseek.com/v1"
api_key = "sk-706577057fea4011a7755270d8a18ce5"
max_tokens = 8096
temperature = 0.1

# [llm] #deepseek:
# model = "deepseek-chat"
# base_url = ""
# api_key = "sk-706577057fea4011a7755270d8a18ce5"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "deepseek-reasoner"
base_url = "https://api.deepseek.com/v1"
api_key = "sk-706577057fea4011a7755270d8a18ce5"
max_tokens = 8096
temperature = 0.1

# Optional configuration for specific browser configuration
# [browser]
# Whether to run browser in headless mode (default: false)
headless = false
# Disable browser security features (default: true)
disable_security = true
# Extra arguments to pass to the browser
#extra_chromium_args = []
# Path to a Chrome instance to use to connect to your normal browser
# e.g. '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
chrome_instance_path = "C:/Program Files/Google/Chrome/Application"
# Connect to a browser instance via WebSocket
#wss_url = ""
# Connect to a browser instance via CDP
#cdp_url = ""

# Optional configuration, Proxy settings for the browser
# [browser.proxy]
# server = "http://proxy-server:port"
# username = "proxy-username"
# password = "proxy-password"

[manus]  # Add a section for Manus-specific settings
memory_config = { type = "database", database_url = "postgresql://hasnamuss:letmein33@localhost:5432/canada_db" }
